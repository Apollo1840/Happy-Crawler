# Happy-Crawler

There are crawlers made by HC-team. The one I want to introduce you most is the BasicCrawler.

## BasicCrawler

<p align="center"> 
    <img src="https://i.screenshot.net/4wxdjc3" alt="the BC brand" width="200" height="200">
</p>

BasicCrawler is an crawler framework, which can be modified to suit your needs of different web cralwering projects. 

Compare to use requests and BeatifulSoup directly, it has following advantages:

* it has good concealment (harder to be detected and catch)
* it is very convenient for you to deploy multiple tasks. (good for data science projects)
* It has a function which can save webpage source code locally, it is very beneficial for long-term development.

So why not use BasicCrawler for your web crawlering projects?

BasicCrawlerGroup is build on BasicCrawler, which acts like mutiple crawlers working in the same time. 

It is faster, harder to been catch and more stable.
 
## Other crawlers

In this repository, we also showed some of crawlers we build and some of web crawlering projects we did. 

If you like them or want to see more upgrade of them, please press Star at the right up corner, thank you very much!

Or join us !!! 

(contact: 2285664798@qq.com, wechat:zoucongyu1109) 

## Navigation

### 1. BasicCrawler -> bc3.py

It is inside bc3.py, to use BasicCrawler just copy bc3.py to your working directory and:

    from bc3 import BasicCrawler

In bc3_testor.py, you will find how to use BasicCrawler and BasicCrawlerGroup

### 2. other crawlers -> projects

They are in projects folder.

### 3. learning material -> tutorial

It has nothing to do with BasicCrawler, just some learning material of how to build a crawler from scrath.

(A very important tool I often use is Pandas, tutorial about Pandas is in another repo of me: Data-Analysis-Tools)

The coming parts are:
* how to login
* how to use req.pull
* more about BeautifulSoup

## Main contributors:
Apollo1840 (contact: zoucongyu1993@hotmail.com, wechat:zoucongyu1109)

