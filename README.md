# Happy-Crawler

There are crawlers made by HC-team. The one I want to introduce you most is the BasicCrawler.

## BasicCrawler

BasicCrawler is an crawler framework which can be modified to suit your needs of different cralwering projects. 

Compare to use requests and BeatifulSoup directly, it has good concealment, and it is convenient for you to deploy multiple tasks. The function of saving webpage source code is very beneficial for long-term development.

BasicCrawlerGroup is build on BasicCrawler, which acts like mutiple crawlers working in the same time. 

It is fast, hard to catch and stable.
 
## Other crawlers

In this repository, we also showed a part of crawlers we build and web crawlering project we did. 

If you like them or want to see more upgrade of them, please press Star or join us (contact: zoucongyu1993@hotmail.com, wechat:zoucongyu1109) at the right up corner, thank you!

## Navigation

### BasicCrawler (bc3.py)

It is inside bc3.py, to use BasicCrawler just copy bc3.py to your working directory and:

    from bc3 import BasicCrawler

In bc3_testor.py, you will find how to use BasicCrawler and BasicCrawlerGroup

### other crawlers (projects)

They are in projects folder.

### tutorial (tutorial)

It has nothing to do with BasicCrawler, just some learning material of how to build a crawler from scrath.

(A very important tool I often use is Pandas, tutorial about Pandas is in another repo of me: Data-Analysis-Tools)

The coming parts are:
* how to login
* how to use req.pull
* more about BeautifulSoup

    
### dummy_websites
There are some simple demonstrations of html5.


## Main contributors:
Apollo1840 (contact: zoucongyu1993@hotmail.com, wechat:zoucongyu1109)

